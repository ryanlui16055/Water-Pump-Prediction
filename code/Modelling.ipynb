{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piH3cRaXkcpO"
      },
      "source": [
        "### 4 Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVjEhtmblIS2"
      },
      "source": [
        "### 1.1 Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywC4mg0WX1zn"
      },
      "outputs": [],
      "source": [
        "pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syHL_Ac0kqi2"
      },
      "outputs": [],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf_uksxAkhWt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#machine learning\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOHJxI8XlFPb"
      },
      "source": [
        "### 4.1 Support functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bzvfBWBkv1G"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix_plotter (y_test,y_pred):\n",
        "  fig, ax = plt.subplots(figsize=(8,5)) \n",
        "  data = confusion_matrix(y_test, y_pred)\n",
        "  df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "  ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
        "  ax.set_xlabel(\"Predicted\")\n",
        "  ax.set_ylabel (\"Actual\")\n",
        "  ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
        "  ax.set_yticklabels(ax.get_xticklabels(), rotation=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfdOy6LGlNMj"
      },
      "outputs": [],
      "source": [
        "def feature_importances (model, title):\n",
        "  features= X_train.columns\n",
        "  importances = np.round(model.feature_importances_,3) \n",
        "  indices = np.argsort(importances)\n",
        "  num_features = len(features)\n",
        "  fig, ax = plt.subplots(figsize=(10,10)) \n",
        "  plt.barh(range(num_features), importances[indices[-num_features:]],  align='center', color =  '#66c2a5')\n",
        "  plt.yticks(range(num_features), [features[i] for i in indices[-num_features:]])\n",
        "  plt.xlabel('Relative Importance')\n",
        "  plt.title('Feature Importance'+ title)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAb_a3nslTZn"
      },
      "source": [
        "### 4.2 Data insertion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj2o4tNslaYV"
      },
      "outputs": [],
      "source": [
        "training_data_value = pd.read_csv(\"../Data/Training_set_values.csv\")\n",
        "training_data_label = pd.read_csv(\"../Data/Training_set_labels.csv\")\n",
        "testing_data = pd.read_csv(\"../Data/Test_set_values.csv\")\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "final_df = pd.read_csv('Values_Modify.csv')\n",
        "final_df = final_df.drop('Unnamed: 0', axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsZUb1ZIlqyj"
      },
      "source": [
        "### 4.3 Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U6xSomTlppk"
      },
      "outputs": [],
      "source": [
        "#define train and test \n",
        "train_set = final_df [final_df [\"id\"].isin(train_values[\"id\"])]\n",
        "test_set =  final_df  [final_df  [\"id\"].isin(test_values[\"id\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zDx3k4FlaQF"
      },
      "outputs": [],
      "source": [
        "#define X and y for training the model\n",
        "X= train_set.drop(['id', 'status_group'], axis=1)\n",
        "y = train_set['status_group']\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42 , stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4ti5peolvs8"
      },
      "source": [
        "### 4.4 Model detail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "aeeldPMdrfjZ",
        "outputId": "fd685b3f-416a-46ad-b390-69a2d6d53033"
      },
      "outputs": [],
      "source": [
        "#define the models\n",
        "models=[LogisticRegression(max_iter = 1000000,  random_state=42),\n",
        "        KNeighborsClassifier(),\n",
        "        DecisionTreeClassifier( random_state=42),\n",
        "       RandomForestClassifier( random_state=42),\n",
        "       XGBClassifier( random_state=42),\n",
        "        BaggingClassifier( random_state=42), \n",
        "        AdaBoostClassifier( random_state=42),\n",
        "        GradientBoostingClassifier( random_state=42),\n",
        "       CatBoostClassifier( random_state=42)]\n",
        "\n",
        "#create a list of model names\n",
        "names =['Logistic Regression', 'KNN Classifier', 'Decision Tree Classifier', 'Random Forest Classifier',  'XGB Classifier', 'Bagging Classifier', 'AdaBoost Classifier', 'Gradient Boosting Classifier', 'Catboost Classifier']\n",
        "\n",
        "#create empty lists for the accuracy and standard deviation\n",
        "accuracy=[]\n",
        "std = []\n",
        "\n",
        "#peform 10-fold cross validaton on each model and append the results to the list\n",
        "for model in models:\n",
        "  cv = KFold(n_splits=10, shuffle = True,  random_state=1)\n",
        "  n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "  mean_score = np.mean(n_scores)\n",
        "  std_score = np.std(n_scores)\n",
        "  accuracy.append(mean_score)\n",
        "  std.append(std_score)\n",
        "\n",
        "#create a dataframe of the model performances\n",
        "d = {'Model':names,'Accuracy':accuracy, 'Std':std}   \n",
        "score_df = pd.DataFrame(d)\n",
        "score_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeybZ0YMmNNR"
      },
      "source": [
        "### 2.2 Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaRVdUW0lOdr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42 , stratify=y)\n",
        "\n",
        "\n",
        "param_grid = { 'n_estimators': [ 150, 175,  200, 225],\n",
        "             'max_features':['log2', ],\n",
        "             'max_depth' : [30 , 40, 50, 60, 70],      \n",
        "             'min_samples_split':[6, 7, 8, 9, 10]}\n",
        "\n",
        "\n",
        "\n",
        "#Create a based model\n",
        "rf =     RandomForestClassifier( random_state=42, warm_start = True)\n",
        "\n",
        "grid_search_rf = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5,  verbose = 2,  scoring = 'accuracy')\n",
        "\n",
        "#fitmodel\n",
        "grid_search_rf .fit(X_train, y_train)\n",
        "\n",
        "#print best parameters \n",
        "print('Best Score:', grid_search_rf .best_score_)\n",
        "print('Parameters:', grid_search_rf .best_params_)\n",
        "print('Best Model:', grid_search_rf .best_estimator_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oK5XDR1smSZd",
        "outputId": "d987a385-0798-4f19-d7cc-2d3d3c06faea"
      },
      "outputs": [],
      "source": [
        "#score model\n",
        "best_model = RandomForestClassifier(max_depth=30, max_features='log2', min_samples_split=7, n_estimators=225, random_state=42, warm_start=True)\n",
        "\n",
        "#fit and predict\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "\n",
        "#print best model scores on test data\n",
        "print(\"Accuracy score train: {}\".format(accuracy_score(y_train, y_pred_train)))\n",
        "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print()\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "confusion_matrix_plotter(y_test, y_pred)\n",
        "\n",
        "feature_importances(best_model, \" Random forest classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHUGF_semxGH"
      },
      "source": [
        "### 2.3 Xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHVXWSPVmwgq"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets: test size 0.2\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "param_grid = { 'n_estimators': [ 200, ],\n",
        "              'colsample_bytree' :[  0.3, ],\n",
        "              'eta': [0.2,],\n",
        "             'max_depth': [12]}\n",
        "\n",
        "\n",
        "#Create a based model\n",
        "xgb =     XGBClassifier( random_state=42)\n",
        "\n",
        "grid_search_xgb = GridSearchCV(estimator = xgb, param_grid = param_grid, cv = 5,  verbose = 2,  scoring = 'accuracy')\n",
        "\n",
        "#fitmodel\n",
        "grid_search_xgb .fit(X_train, y_train,  eval_metric = 'mlogloss',)\n",
        "\n",
        "#print best parameters \n",
        "print('Best Score:', grid_search_xgb .best_score_)\n",
        "print('Parameters:', grid_search_xgb .best_params_)\n",
        "print('Best Model:', grid_search_xgb .best_estimator_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1u8XFWiznFcK",
        "outputId": "f779fb19-3466-4468-ebea-0c6707a45045"
      },
      "outputs": [],
      "source": [
        "#score model\n",
        "best_model = XGBClassifier( random_state=42, n_estimators = 200, colsample_bytree = 0.3, eta = 0.2, max_depth = 12 )\n",
        "best_model .fit(X_train, y_train,  eval_metric = 'mlogloss',)\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "\n",
        "\n",
        "#print best model scores on test data\n",
        "print(\"Accuracy score train: {}\".format(accuracy_score(y_train, y_pred_train)))\n",
        "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print()\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "confusion_matrix_plotter(y_test, y_pred)\n",
        "\n",
        "feature_importances(best_model, \" XGBoost classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmNk68Funbcn"
      },
      "source": [
        "### 2.4 Catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGCAhK_mnfG5"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets: test size 0.2\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42 , stratify=y)\n",
        "\n",
        "\n",
        "param_grid = { 'max_depth': [ 7,8,9],\n",
        "              'iterations': [1000, 750],\n",
        "              'rsm' :[0.3, 0.2]}\n",
        "\n",
        "#Create a based model\n",
        "cat  =     CatBoostClassifier( random_state=42)\n",
        "\n",
        "grid_search_cat = GridSearchCV(estimator = cat, param_grid = param_grid, cv = 5,  verbose = 2,  scoring = 'accuracy')\n",
        "\n",
        "#fitmodel\n",
        "grid_search_cat .fit(X_train, y_train)\n",
        "\n",
        "#print best parameters \n",
        "print('Best Score:', grid_search_cat .best_score_)\n",
        "print('Parameters:', grid_search_cat .best_params_)\n",
        "print('Best Model:', grid_search_cat .best_estimator_)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-1WSSrAnj3x"
      },
      "outputs": [],
      "source": [
        "#score model\n",
        "best_model = CatBoostClassifier( random_state=42, rsm = 0.2, max_depth =9, iterations = 1000)\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_train = best_model.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ghD1NaPvQQ5_",
        "outputId": "eca01e46-4f92-4450-ead5-7fb7f1f2bf45"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#print best model scores on test data\n",
        "print(\"Accuracy score train: {}\".format(accuracy_score(y_train, y_pred_train)))\n",
        "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print()\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "confusion_matrix_plotter(y_test, y_pred)\n",
        "\n",
        "feature_importances(best_model, \" CatBoost classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJn61b07oHcG"
      },
      "source": [
        "### 2.5 Bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlAJcfB3oPNO"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets: test size 0.2\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42)\n",
        "\n",
        "\n",
        "param_grid = { 'n_estimators': [100, 200, 300, 400, 500, 700, 800, 900, 1000],\n",
        "              'max_features': [0.2, 0.25, 0.3, 0.35, 0.4]}\n",
        "\n",
        "    \n",
        "\n",
        "#Create a based model\n",
        "bag  =      BaggingClassifier( random_state=42, )\n",
        "\n",
        "grid_search_bag = RandomizedSearchCV(estimator = bag, param_distributions = param_grid, cv =5, n_iter = 45,\n",
        "                               verbose = 2, scoring = 'accuracy')\n",
        "\n",
        "#fitmodel\n",
        "grid_search_bag.fit(X_train, y_train )\n",
        "\n",
        "#print best parameters \n",
        "print('Best Score:', grid_search_bag.best_score_)\n",
        "print('Parameters:', grid_search_bag.best_params_)\n",
        "print('Best Model:',grid_search_bag .best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "xJnLewHroZxW",
        "outputId": "e11c08ee-c0b8-437b-d108-21374407d9bc"
      },
      "outputs": [],
      "source": [
        "#get scores\n",
        "best_model = BaggingClassifier( random_state=42, n_estimators = 1000, max_features = 0.4 )\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "\n",
        "\n",
        "#print best model scores on test data\n",
        "print(\"Accuracy score train: {}\".format(accuracy_score(y_train, y_pred_train)))\n",
        "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print()\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "confusion_matrix_plotter(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7JlZb_VpQjH"
      },
      "source": [
        "### 2.6 Mixed vote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl0Js8PAowx7"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(max_depth=30, max_features='log2', min_samples_split=7, n_estimators=225, random_state=42, warm_start=True)\n",
        "xgb = XGBClassifier(max_depth =12, n_estimators= 200, colsample_bytree = 0.3, eta = 0.2, random_state = 42) \n",
        "cat = CatBoostClassifier(max_depth = 9, rsm = 0.2, iterations = 1000, random_state = 42)\n",
        "bag = BaggingClassifier(max_features=0.4, n_estimators=1000, random_state=42) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k89gDzCbpcTL",
        "outputId": "acbb53e1-07c5-430f-cb2d-d28e958d1355"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets: test size 0.2\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "vc = VotingClassifier([('rf', rf), ('xgb', xgb),('cat', cat), ('bag', bag)], voting = 'soft')\n",
        "                       \n",
        "\n",
        "#fit and predict\n",
        "vc.fit(X_train , y_train)\n",
        "pred= vc .predict(X_test)\n",
        "pred_train = vc .predict(X_train)\n",
        "\n",
        "\n",
        "#print best model scores on test data\n",
        "print(\"Accuracy score train: {}\".format(accuracy_score(y_train ,pred_train)))\n",
        "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, pred)))\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "#heatmap\n",
        "fig, ax = plt.subplots(figsize=(8,5)) \n",
        "data = confusion_matrix(y_test, pred)\n",
        "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel (\"Actual\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
        "ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pbXJPxMpq3C"
      },
      "source": [
        "###2.7  Xgboost vote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGYip9i8pn0e"
      },
      "outputs": [],
      "source": [
        "xgb1 = XGBClassifier(max_depth =12, n_estimators= 200, colsample_bytree = 0.3, eta = 0.2, random_state = 42)\n",
        "xgb2 = XGBClassifier(max_depth =12, n_estimators= 200, colsample_bytree = 0.3, eta = 0.2, random_state = 2) \n",
        "xgb3 = XGBClassifier(max_depth =12, n_estimators= 200, colsample_bytree = 0.3, eta = 0.2, random_state = 142) \n",
        "xgb4 = XGBClassifier(max_depth =12, n_estimators= 200, colsample_bytree = 0.3, eta = 0.2, random_state = 33 )\n",
        "xgb5 = XGBClassifier(max_depth =12, n_estimators= 200, colsample_bytree = 0.3, eta = 0.2, random_state = 678)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "peDD9dFDpnub",
        "outputId": "e9e5df7c-390d-420d-d216-f2d087522ae7"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets: test size 0.2\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "vc = VotingClassifier([('xgb1', xgb1), ('xgb2', xgb2), ('xgb3', xgb3), ('xgb4', xgb4), ('xgb5', xgb5)], voting = 'soft')\n",
        "                       \n",
        "\n",
        "#fit and predict\n",
        "vc.fit(X_train , y_train)\n",
        "pred= vc .predict(X_test)\n",
        "pred_train = vc .predict(X_train)\n",
        "\n",
        "\n",
        "#print best model scores on test data\n",
        "print(\"Accuracy score train: {}\".format(accuracy_score(y_train ,pred_train)))\n",
        "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, pred)))\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "#heatmap\n",
        "fig, ax = plt.subplots(figsize=(8,5)) \n",
        "data = confusion_matrix(y_test, pred)\n",
        "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel (\"Actual\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
        "ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K25sw2nHp00q"
      },
      "source": [
        "### 2.8 Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ybROFQMpp9Oa",
        "outputId": "883a6f39-7650-4c52-b1d7-0817fdd6770a"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets: test size 0.2\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "stack = StackingClassifier([('rf', rf), \n",
        "                              ('xgb', xgb),\n",
        "                              ('cat', cat),\n",
        "                           ('bag', bag)], final_estimator=LogisticRegression())\n",
        "                       \n",
        "\n",
        "#fit and predict\n",
        "stack.fit(X_train , y_train)\n",
        "pred= stack.predict(X_test)\n",
        "pred_train = stack.predict(X_train)\n",
        "\n",
        "\n",
        "#print best model scores on test data\n",
        "print(\"Accuracy score train: {}\".format(accuracy_score(y_train ,pred_train)))\n",
        "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, pred)))\n",
        "\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "#heatmap\n",
        "fig, ax = plt.subplots(figsize=(8,5)) \n",
        "data = confusion_matrix(y_test, pred)\n",
        "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel (\"Actual\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
        "ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHi3HFAaqEGF"
      },
      "source": [
        "### 2.9 Weighted vote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oftPIVaXqDqy",
        "outputId": "e56cdc7c-8c66-4a75-bcc3-965386bd13df"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets: test size 0.2\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "vc = VotingClassifier([('rf', rf), ('xgb', xgb),('cat', cat), ('bag', bag)], voting = 'soft', weights = [0.85, 1, 0.85, 0.75])\n",
        "                       \n",
        "\n",
        "#fit and predict\n",
        "vc.fit(X_train , y_train)\n",
        "pred= vc .predict(X_test)\n",
        "pred_train = vc .predict(X_train)\n",
        "\n",
        "\n",
        "#print best model scores on test data\n",
        "print(\"Accuracy score train: {}\".format(accuracy_score(y_train ,pred_train)))\n",
        "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, pred)))\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "#heatmap\n",
        "fig, ax = plt.subplots(figsize=(8,5)) \n",
        "data = confusion_matrix(y_test, pred)\n",
        "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel (\"Actual\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
        "ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG3xN8DDqPPR"
      },
      "outputs": [],
      "source": [
        "#fit on foll training set\n",
        "vc.fit(X , y)\n",
        "\n",
        "#predict\n",
        "submission = test_set.drop(['id', 'status_group'], axis=1)\n",
        "submission['status_group'] = vc.predict(submission)\n",
        "\n",
        "#bring the id column back\n",
        "submission['id'] = test_set['id']\n",
        "\n",
        "#create df for submission and save\n",
        "best_submission = submission[['id', 'status_group']]\n",
        "best_submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AtjUALccDsbH",
        "outputId": "6da35dd5-c794-4c99-81c6-671778b74b3e"
      },
      "outputs": [],
      "source": [
        "best_submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUnNPaPtr7EG"
      },
      "outputs": [],
      "source": [
        "#best_submission.to_csv('best_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmhdyxrUqfXr"
      },
      "source": [
        "# 3 Result overview"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMYC7J1eRZYwE0HcbL+C9Iz",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "15zvYPlJaP-TrEfDXMa5cqDuurqA-2X_G",
      "name": "waterpumps -modelling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
